{"id":"82kPqomaPXmNomrHzpZWfbkQxiiNUBTAYKxHR5qZBEpf","title":"Hacker News: Show HN","displayTitle":"HN Show","url":"https://hnrss.org/show?points=60","feedLink":"https://news.ycombinator.com/shownew","isQuery":false,"isEmpty":false,"isHidden":false,"itemCount":18,"items":[{"title":"Show HN: Open-Source DocumentAI with Ollama","url":"https://rlama.dev/","date":1741399933,"author":"Dontizi","guid":109,"unread":true,"content":"<p>Open-source project. All rights reserved.</p>","contentLength":41,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43296918"},{"title":"Show HN: Rust Vector and Quaternion Lib","url":"https://github.com/David-OConnor/lin-alg","date":1741293167,"author":"the__alchemist","guid":108,"unread":true,"content":"<p>I use this library I made for Vectors and Quaternions in many personal projects. I've open-sourced it, in case anyone else would get use out of it.</p><p>I use this on various projects, including quadcopter firmware, a graphics engine, a cosmology simulation, and several molecular dynamics applications. No_std compatible.</p>","contentLength":316,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43284811"},{"title":"Show HN: Shelgon: A Framework for Building Interactive REPL Shells in Rust","url":"https://github.com/NishantJoshi00/shelgon","date":1741289532,"author":"cat-whisperer","guid":107,"unread":true,"content":"<p>I've been working on Shelgon, a framework that lets you build your own custom REPL shells and interactive CLI applications in Rust.</p><p>- Create a custom shell with only a few lines of code\n- Build interactive debugging tools with persistent state between commands\n- Develop domain-specific language interpreters with shell-like interfaces\n- Add REPL capabilities to existing applications</p><p>Getting started is straightforward - implement a single trait that handles your command execution logic, and Shelgon takes care of the terminal UI, input handling, and async runtime integration.</p><p>For example, a simple echo shell takes less than 50 lines of code, including a full implementation of command history, cursor movement, and tab completion.</p>","contentLength":732,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43284227"},{"title":"Show HN: Open-source, native audio turn detection model","url":"https://github.com/pipecat-ai/smart-turn","date":1741285248,"author":"kwindla","guid":106,"unread":true,"content":"<p>Our goal with this project is to build a completely open source, state of the art turn detection model that can be used in any voice AI application.</p><p>I've been experimenting with LLM voice conversations since GPT-4 was first released. (There's a previous front page Show HN about Pipecat, the open source voice AI orchestration framework I work on. [1])</p><p>It's been almost two years, and for most of that time, I've been expecting that someone would \"solve\" turn detection. We all built initial, pretty good 80/20 versions of turn detection on top of VAD (voice activity detection) models. And then, as an ecosystem, we kind of got stuck.</p><p>A few production applications have recently started using Gemini 2.0 Flash to do context aware turn detection. [2] But because latency is ~500ms, that's a more complicated approach than using a specialized model. The team at LiveKit released an open weights model that does text-based turn detection. [3] I was really excited to see that, but I'm not super-optimistic that a text-input model will ever be good enough for this task. (A good rule of thumb in deep learning is that you should bet on end-to-end.)</p><p>So ... I spent Christmas break training several little proof of concept models, and experimenting with generating synthetic audio data. So, so, so much fun. The results were promising enough that I nerd-sniped a few friends and we started working in earnest on this.</p><p>The model now performs really well on a subset of turn detection tasks. Too well, really. We're overfitting on a not-terribly-broad initial data set of about 8,000 samples. Getting to this point was the initial bar we set for doing a public release and seeing if other people want to get involved in the project.</p><p>There are lots of ways to contribute. [4]</p><p>Medium-term goals for the project are:</p><pre><code>  - Support for a wide range of languages\n  - Inference time of &lt;50ms on GPU and &lt;500ms on CPU\n  - Much wider range of speech nuances captured in training data\n  - A completely synthetic training data pipeline. (Maybe?)\n  - Text conditioning of the model, to support \"modes\" like credit card, telephone number, and address entry.\n</code></pre>\nIf you're interested in voice AI or in audio model ML engineering, please try the model out and see what you think. I'd love to hear your thoughts and ideas.","contentLength":2287,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43283317"},{"title":"Show HN: CodeTracer – A time-traveling debugger implemented in Nim and Rust","url":"https://github.com/metacraft-labs/codetracer","date":1741271410,"author":"alehander42","guid":105,"unread":true,"content":"<p>We are presenting CodeTracer - a user-friendly time-traveling debugger designed to support a wide range of programming languages:</p><p>CodeTracer records the execution of a program into a sharable self-contained trace file. You can load the produced trace files in a GUI environment that allows you to move forward and backward through the execution and to examine the history of all memory locations. They say a picture is worth a thousand words — well, a video is even better! Watch the demo below to see CodeTracer in action:</p><p>The initial release is limited to the Noir programming language, but CodeTracer uses an open format for its trace files and we've started community-driven projects which aim to add support for Ruby and Python.</p><p>We are also developing an alternative back-end, capable of working with RR recordings, which will make CodeTracer suitable for debugging large-scale programs in a variety of system programming languages such as C/C++, Rust, Nim, D, Zig, Go, Fortran and FreePascal.</p>","contentLength":997,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43280615"},{"title":"Show HN: Leaflet.pub – a web app for creating and sharing rich documents","url":"https://news.ycombinator.com/item?id=43269928","date":1741197329,"author":"jpereira","guid":104,"unread":true,"content":"Hi HN!<p>For the last 8 months we've been working on leaflet.pub, a web app for making delightful documents. We're trying to strike a balance between Notion and Google Docs — very fast, ultralight and easy to share, but also supporting rich blocks and multiple pages.</p><p>Weirdly, none of the many notetaking/document apps that we could find hit this combination, so we made Leaflet. With it you can:</p><p>- Instantly create a doc, without an account\n- Share read and edit links\n- Sign-in with email to sync your docs to different devices\n- Add rich blocks, like canvases, subpages, rsvps, and polls</p><p>It's really useful for one-off collaborations, running events, or just when you need a blank page without having to buy into a whole organizational system.</p><p>We also spent a lot of time making sure Leaflets look good. We've found that there's a pretty blurry boundary between a document and a website, so making something that people can feel proud to publish online was key.</p><p>Here's a couple examples!</p><p>Some technical details that might be interesting:</p><p>- We do sync and all our client-side state via Replicache, which I really love!\n- Data is modeled as a set of facts about entities, a la Datomic, forming a graph. This has been flexible enough for us to quickly build new features, like canvases and nested pages, without committing to a single document structure.\n- We use ProseMirror, but not for the entire document. Instead every text block is a separate ProseMirror instance. This lets us keep the document structure in our database and our schema, without having to dive into ProseMirror's every time we want to modify things.</p><p>- Better home and document organizing features — things like search, tagging, collections etc.\n- We're really excited about ATProto and Bluesky and are working on a set of lexicons and an AppView for document publishing! This will include a lexicon for rich text documents, as well as one publications, and some concept of memberships or subscriptions.\n- More blocks! Tables, code blocks, etc.</p><p>Some things we're particularly proud of:</p><p>- Our list handling\n- Custom theming\n- Keyboard handling on iOS Safari (and generally works excellently on mobile)\n- Side-scrolling multi-page interface\n- Works as a PWA!</p><p>Some things that still need work:</p><p>- While faster than others, still a lot of work we can do on performance, both speed when working with very large documents and loading docs generally\n- Drag and drop and selection in general could be a lot nicer\n- Keyboard navigation across multiple pages\n- Multiplayer cursors, and generally real-time sync could be sped up greatly leveraging CRDTs (we already use YJS, just could move updates around faster)</p>","contentLength":2662,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43269928"},{"title":"Show HN: Beating Pokemon Red with RL and <10M Parameters","url":"https://drubinstein.github.io/pokerl/","date":1741194429,"author":"drubs","guid":103,"unread":true,"content":"<p>After spending hundreds of hours, we're excited to finally share our progress in developing a reinforcement learning system to beat Pokémon Red. Our system successfully completes the game using a policy under 10M parameters, PPO, and a few novel techniques. With the release of Claude Plays Pokémon, now feels like the perfect time to showcase our work.</p><p>We'd love to get feedback!</p>","contentLength":381,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43269330"},{"title":"Show HN: I Built a Telegraph Simulator","url":"https://telegraph.13ug1mb.com/","date":1741125608,"author":"leugim","guid":102,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43260251"},{"title":"Show HN: Time travel debugging AI for more reliable vibe coding","url":"https://nut.new/","date":1741114424,"author":"bhackett","guid":101,"unread":true,"content":"<p>Fix tough bugs and get your app working right.</p>","contentLength":46,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43258585"},{"title":"Show HN: Appstat – Process Monitor for Windows","url":"https://pragmar.com/appstat/","date":1741101872,"author":"pragmar","guid":100,"unread":true,"content":"<p>Monitor CPU, memory, disk, and thread metrics in real-time for running applications.\n                    Quickly identify resource bottlenecks, memory leaks, and performance spikes without\n                    interrupting your workflow. The graphical interface shows exactly what's happening\n                    when performance issues occur.</p><p>Built for developers,  combines detailed monitoring with a clean interface. Select any running application to see its performance data instantly. Features include dark/light modes, always-on-top option, and exportable logs for team analysis.</p><p>\n                    You can use  on any computer, including a computer in a commercial organization.\n                    <strong>There is no need to register or pay to use the software.</strong></p>","contentLength":761,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43255855"},{"title":"Show HN: Fork of Claude-code working with local and other LLM providers","url":"https://github.com/dnakov/anon-kode","date":1741095312,"author":"npace12","guid":98,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43254351"},{"title":"Show HN: Sonauto API – Generative music for developers","url":"https://sonauto.ai/developers","date":1741022246,"author":"zaptrem","guid":97,"unread":true,"content":"<!DOCTYPE html>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43244166"},{"title":"Show HN: Agents.json – OpenAPI Specification for LLMs","url":"https://github.com/wild-card-ai/agents-json","date":1741021319,"author":"yompal","guid":96,"unread":true,"content":"<p>Hey HN, we’re building an open specification that lets agents discover and invoke APIs with natural language, built on the OpenAPI standard. agents.json clearly defines the contract between LLMs and API as a standard that's open, observable, and replicable.\nHere’s a walkthrough of how it works: <a href=\"https://youtu.be/kby2Wdt2Dtk?si=59xGCDy48Zzwr7ND\" rel=\"nofollow\">https://youtu.be/kby2Wdt2Dtk?si=59xGCDy48Zzwr7ND</a>.</p><p>1. An agents.json file describes how to link API calls together into outcome-based tools for LLMs. This file sits alongside an OpenAPI file.</p><p>2. The agents.json SDK loads agents.json files as tools for an LLM that can then be executed as a series of API calls.</p><p>Why is this worth building?\nDevelopers are realizing that to use tools with their LLMs in a stateless way, they have to implement an API manually to work with LLMs. We see devs sacrifice agentic, non-deterministic behavior for hard-coded workflows to create outcomes that can work. agents.json lets LLMs be non-deterministic for the outcomes they want to achieve and deterministic for the API calls it takes to get there.</p><p>We’ve put together some real examples if you're curious what the final output looks like. Under the hood, these LLMs have the same system prompt and we plug in a different agents.json to give access to different APIs. It’s all templatized.</p><p>We really wanted to solve real production use cases, and knew this couldn’t just be a proxy. Our approach allows you to make API calls from your own infrastructure. The open-source specification + runner package make this paradigm possible. Agents.json is truly stateless; the client manages all memory/state and it can be deployed on existing infra like serverless environments.</p><p>You might be wondering -  Why can’t I just put that in the LLM’s context?</p><p>We thought so too, at first, when building an agent with access to Gmail. But putting the API spec into LLM context gave us poor accuracy in tool selection and in tool calling. Even with cutting down our output space to 5-10 endpoints, we’d see the LLMs fail to select the right tool. We wanted the LLM to just work given an outcome rather than having it reason each time which series of API calls to make.</p><p>The Gmail API, for example, has endpoints to search for threads, list the emails in a thread, and reply with an email given base64 RFC 822 content. All that has to happen in order with the right arguments for our agent to reply to a thread. We found that APIs are designed for developers, not for LLMs.</p><p>So we implemented agents.json. It started off as a config file we were using internally that we slowly started adding features to like auth registration, tool search, and multiple API sources. 3 weeks ago, Dharmesh (CTO of Hubspot) posted about the concept of a specification that could translate APIs for LLMs. It sounded a lot like what we already had working internally and we decided to make it open source. We built agents.json for ourselves but we’re excited to share it.</p><p>In the weeks since we’ve put it out there, agents.json has 10 vetted API integrations (some of them official) and more are being added every day. We recently made the tool search and custom collection platform free for everyone so it’s even easier for devs to scale the number of tools. (<a href=\"https://wild-card.ai\">https://wild-card.ai</a>)</p><p>Please tell us what you think! Especially if you’re building agents or creating APIs!</p>","contentLength":3318,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43243893"},{"title":"Show HN: Open-Source Windows AI assistant that uses Word, Excel through COM","url":"https://github.com/Alkali-Sim/SmartestKid","date":1741018228,"author":"edmgood","guid":95,"unread":true,"content":"<p>This started off as a project to understand how to get LLMs to interface with more traditional desktop softwares.</p><p>We were especially interested in tools related to schematic drafting and molecular simulation.</p><p>Decided to explore COM automation for more traditional Windows softwares as a starting point! Been using it to help some friends automate simple excel workflows. Thought we'd share!</p>","contentLength":388,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43243153"},{"title":"Show HN: Knowledge graph of restaurants and chefs, built using LLMs","url":"https://theophilecantelob.re/blog/2025/foudinge/","date":1741016600,"author":"theophilec","guid":94,"unread":true,"content":"<p>For French restaurant intel, <a href=\"https://lefooding.com\" rel=\"external nofollow noopener\" target=\"_blank\">lefooding.com</a> is the definitive data source. Their anonymous critics conduct systematic reviews of establishments across France (and now Belgium), documenting their findings in a witty - if peculiar - style. Beyond choosing the place for a delicious night out, they can be used to map and understand France’s culinary network.</p><p>A network is composed of nodes and edges. Nodes represent entities, such as people or restaurants. Edges represent the relationships between people and restaurants, or absence thereof. For the French restaurant scene, nodes represent both people and restaurants. A person node is connected to a restaurant if that person is known to have worked at the restaurant.</p><p>Restaurants with very many neighbor nodes (nodes connected to it) are restaurants whose alumni go on to create and work in other prestigious restaurants. This is the case of <a href=\"https://www.ducasse-paris.com/\" rel=\"external nofollow noopener\" target=\"_blank\">Ducasse</a> (ok, not a restaurant but a placeholder for all the restaurants in the Ducasse brand), <a href=\"https://www.mandarinoriental.com/fr\" rel=\"external nofollow noopener\" target=\"_blank\">Mandarin Oriental</a> (technically the restaurant is called Sur Mesure) or <a href=\"https://www.septime-charonne.fr/\" rel=\"external nofollow noopener\" target=\"_blank\">Septime</a>.</p><p>To visualize and analyse this network, I combine information contained in reviews of restaurants across France by <a href=\"https://lefooding.com\" rel=\"external nofollow noopener\" target=\"_blank\">LeFooding.com</a>’s critics. Most reviews contain information about the staff and their CV.</p><p>Take this (shortened) review of <a href=\"https://lefooding.com/restaurants/grenat\" rel=\"external nofollow noopener\" target=\"_blank\">Grenat</a> (emphasis mine):</p><blockquote><p>À l’enseigne de Grenat,  et  ont le rouge aux joues et aux murs. <strong>Après avoir officié à La Brasserie Communale, où ils se sont rencontrés</strong>, les deux compères font désormais feu de tout bois en plein centre de Marseille, où <strong>Antoine veille au grain autour des tables en bois blond, convoyant les plats que Neil embrase à tout-va depuis l’âtre derrière le comptoir</strong>. Des huîtres aux pièces viandardes, […]</p></blockquote><p>and LeFooding.com’s English version:</p><blockquote><p>At Grenat,  and  are bathed in an ardent red glow, much like the pomegranate-toned walls of their space. <strong>After working together at La Brasserie Communale, where they first met</strong>, the duo is now firing on all cylinders in the heart of Marseille, where <strong>Antoine tends to guests seated around blonde wood tables, delivering dishes ignited by Neil behind the bar.</strong> From oysters to prime cuts of red meat, […]</p></blockquote><p>Notice that the review mentions the restaurant staff, their prior experience at  and gives their roles in the restaurant. All of this information should be included in the network. Using OpenAI’s gpt4o-mini model with its structured generation functionality, I can extract information from the 1800 publicly available <a href=\"https://lefooding.com\" rel=\"external nofollow noopener\" target=\"_blank\">LeFooding.com</a> reviews going back four years. Instead of the order of 1800 “current” staff-restaurant relationships, I uncovered over 5000 links, enriching our analysis with all possible information from the reviews.</p><p>I combined the extracted information into a graph you can explore below (or <a href=\"https://ouestware.gitlab.io/retina/1.0.0-beta.4/#/graph/?url=https%3A%2F%2Fgist.githubusercontent.com%2Ftheophilec%2F351f17ece36477bc48438d5ec6d14b5a%2Fraw%2Ffa85a89541c953e8f00d6774fe42f8c4bd30fa47%2Fgraph.gexf&amp;r=x&amp;sa=re&amp;ca[]=t&amp;ca[]=ra-s&amp;st[]=u&amp;st[]=re&amp;ed=u\" rel=\"external nofollow noopener\" target=\"_blank\">click here</a>) below. To get started in exploring look for , Antoine, Neil or  and other restaurants I’ve mentioned. </p><p>The network has over 5000 nodes and as many edges. In the visualization, green nodes represent staff and purple nodes represent restaurants. Larger nodes have a higher degree (more neighbors). Edges link restaurants and staff. You can it below. Look for your favorite restaurant, or click around to discover the connected components in the graph.</p><p>To get here, I scraped data from <a href=\"https://lefooding.com\" rel=\"external nofollow noopener\" target=\"_blank\">LeFooding.com</a>, extracted the desired information from the reviews, built the graph and finally made the visualization. The code used is available at <a href=\"https://github.com/theophilec/foudinge\" rel=\"external nofollow noopener\" target=\"_blank\">theophilec/foudinge</a>.</p><p>The crux of the approach is extracting the information is a structured way. Indeed, I need an easy was of building the graph and knowing which restaurants and people are related. Large Language Models (LLMs) are excellent in understanding a text, and can answer questions like “Where did Antoine Joannier work before Grenat?” with the Grenat review. However, if we ask for the information is a structured format like a JSON object, they struggle to reliably give useful answers.</p><p>For instance, the desired output for the Grenat review could be something like this:</p><div><div><pre><code></code></pre></div></div><p>This is the art of .</p><p>There are several approaches to this problem. First, one can . Second, and in combination with the first approach, one can retry inference until the response parses in the desired schema. While this can work as a one-off when hacking a configuration file, it won’t work for almost 2000 reviews.</p><p>Another approach uses the logits of the model. These define the sampling distributions for the next token. They can be modified at inference to force the generated tokens to build into a response respecting a defined structure. Behind the scences, this relies on regular expressions and finite state machines (the same techniques used when  JSON). When using such techniques, you prompt the model however you want (and give the schema to inference API) and the output provably respects the desired structure 100% of the time, and can be used reliably downstream.</p><p>The  library built by <a href=\"https://dottxt.co/\" rel=\"external nofollow noopener\" target=\"_blank\">.txt</a> makes this possible for your favorite open model, such as . It also wraps OpenAI’s implementation of this in its API.</p><div><div><pre><code></code></pre></div></div><p>I put Mistral, Meta and OpenAI head to head. Both Llama3.2-3B and Mistral-7B-v0.3 had a tendency to hallucinate fake people and related restaurants. In the end, I opted for OpenAI gpt4o-mini, which was also much faster. But even gpt4o-mini was susceptible to mistakes, which makes me optimistic that better prompting, an improved schema design will allow me to reproduce the results with Mistral or Llama (future work).</p><p>The total cost of inference over 2000 reviews with gpt4o-mini with its structured generation endpoint is less that 1€!</p><p>I used <a href=\"https://gephi.org/gephi-lite\" rel=\"external nofollow noopener\" target=\"_blank\">gephi-lite</a> to create work on the visualization. The key step was spatialization, which defines a spatial layout of the graph that makes sense given the information contained in the graph. In our case, I used the force simulation setting which sends connected nodes close and nodes with larger degree to the center. The embedded visualization runs using WebGL thanks to the <a href=\"https://ouestware.gitlab.io/retina\" rel=\"external nofollow noopener\" target=\"_blank\">Retina</a> project</p><p>In order to handle duplicates and eliminating some obvious errors visible on the graph once visualized I asked Claude 3.7 Sonnet to create a simple web app to allow me to edit the inferred entities while keeping the structure intact (as well as the encoding issues caused by sqlite/myself). It only took 2 iterations to get it working as I wanted, and then a few more iterations to get full-text search and some other features. It uses Flask and pure JS in jinja templates. It is available on Github at <a href=\"https://github.com/theophilec/foudinge-scrub\" rel=\"external nofollow noopener\" target=\"_blank\"></a> There are still a few duplicates to fix, which I’ll get around to (maybe).</p><p>All the code used for scraping (using sqlite, asyncio and aiohttp), the inference (using outlines), the prompt and the Pydantic Schema are available on Github at <a href=\"https://github.com/theophilec/foudinge\" rel=\"external nofollow noopener\" target=\"_blank\">theophilec/foudinge</a>.</p><p>This project illustrates how LLMs can be used to extract information from rich sources of textual data, in this instance restaurant reviews. I am very happy with the tools I chose. A good next step is to get all this running of open models, locally or in a public cloud.</p><p><em>Thanks to Adrien Bocquet and Clotilde Bukato for proofreading earlier versions of this post.</em></p>","contentLength":7111,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43242818"},{"title":"Show HN: Open-source Deep Research across workplace applications","url":"https://github.com/onyx-dot-app/onyx","date":1741015102,"author":"yuhongsun","guid":93,"unread":true,"content":"<p>I’ve been using deep research on OpenAI and Perplexity and it’s been just amazing at gathering data across a lot of related and chained searches. Just earlier today, I asked “What are some marquee tech companies / hot startups (not including the giants like FAAMG, Samsung, Nvidia etc.)”. It’s a pretty involved question and looking up “marquee tech startups” or \"hot tech startups\" on Google gave me nothing useful. Deep research on both ChatGPT and Perplexity gave really high quality responses with ChatGPT siding on slightly larger scaleups and Perplexity siding more on up and coming companies.</p><p>Given how useful AI research agents are across the internet, we decided to build an open-source equivalent for the workplace since a ton of questions at work also cannot be easily resolved with a single search. Onyx supports deep research connected to company applications like Google Drive, Salesforce, Sharepoint, GitHub, Slack, and 30+ others.</p><p>For example, an engineer may want to know “What’s happening with the verification email failure?” Onyx’s AI agent would first figure out what it needs to answer this question: What is the cause of the failure, what has been done to address it, has this come up before, and what’s the latest status on the issue. The agent would run parallel searches through Confluence, email, Slack, and GitHub to get the answers to these then combine them to build a coherent overview. If the agent finds that there was a technical blocker that will delay the resolution, it will adjust mid-flight and research to get more context on the blocker.</p><p>P.S. There’s a lot of cool technical details behind building a system like this so I’ll continue the conversation in the comments.</p>","contentLength":1734,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43242551"},{"title":"Show HN: FlakeUI","url":"https://github.com/tearflake/flake-ui","date":1740979742,"author":"tearflake","guid":92,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43238570"},{"title":"Show HN: Tangled – Git collaboration platform built on atproto","url":"https://blog.tangled.sh/intro","date":1740946455,"author":"icy","guid":91,"unread":true,"content":"<p><a href=\"https://tangled.sh\" rel=\"nofollow\">Tangled</a> is a new social-enabled Git collaboration\nplatform, built on top of the <a href=\"https://atproto.com\" rel=\"nofollow\">AT Protocol</a>. We\nenvision a place where developers have complete ownership of their code,\nopen source communities can freely self-govern and most importantly,\ncoding can be social and fun again.</p><p>There are several models for decentralized code collaboration platforms,\nranging from ActivityPub’s (Forgejo) federated model, to Radicle’s\nentirely P2P model. Our approach attempts to be the best of both worlds\nby adopting atproto—a protocol for building decentralized social\napplications with a central identity.</p><p>Our approach to this is the idea of “knots”. Knots are lightweight,\nheadless servers that enable users to host Git repositories with ease.\nKnots are designed for either single or multi-tenant use which is\nperfect for self-hosting on a Raspberry Pi at home, or larger\n“community” servers. By default, Tangled provides managed knots where\nyou can host your repositories for free.</p><p>The <a href=\"https://docs.bsky.app/docs/advanced-guides/federation-architecture#app-views\" rel=\"nofollow\">App View</a> at <a href=\"https://tangled.sh\" rel=\"nofollow\">tangled.sh</a> acts as a\nconsolidated “view” into the whole network, allowing users to access,\nclone and contribute to repositories hosted across different knots—completely seamlessly.</p><p>Tangled is still in its infancy, and we’re building out several of its\ncore features as we <a href=\"https://tangled.sh/@tangled.sh/core\" rel=\"nofollow\">dogfood it ourselves</a>. We developed these\nthree tenets to guide our decisions:</p><ol><li>No compromise on user-experience</li></ol><p>Collaborating on code isn’t easy, and the tools and workflows we use\nshould feel natural and stay out of the way. Tangled’s architecture\nenables common workflows to work as you’d expect, all while remaining\ndecentralized.</p><p>We believe that atproto has greatly simplfied one of the hardest parts\nof social media: having your friends on it. Today, we’re rolling out\ninvite-only access to Tangled—join us on IRC at  on\n<a href=\"https://libera.chat\" rel=\"nofollow\">libera.chat</a> and we’ll get you set up.</p>","contentLength":1844,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43234544"}],"tags":["dev"]}