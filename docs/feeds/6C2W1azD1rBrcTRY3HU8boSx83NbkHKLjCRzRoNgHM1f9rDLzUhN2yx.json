{"id":"6C2W1azD1rBrcTRY3HU8boSx83NbkHKLjCRzRoNgHM1f9rDLzUhN2yx","title":"MLOps.community","displayTitle":"Podcast - MLOps","url":"https://anchor.fm/s/174cb1b8/podcast/rss","feedLink":"https://mlops.community/","isQuery":false,"isEmpty":false,"isHidden":false,"items":[{"title":"Machine Learning, AI Agents, and Autonomy // Egor Kraev // #282","url":"https://podcasters.spotify.com/pod/show/mlops/episodes/Machine-Learning--AI-Agents--and-Autonomy--Egor-Kraev--282-e2t6ct4","date":1736341207,"author":"Demetrios Brinkmann","unread":true,"content":"<ituneshack><p>Since three years, <a href=\"https://www.linkedin.com/in/egorkraev/\" target=\"_blank\" rel=\"ugc noopener noreferrer\"><em>Egor</em></a> is bringing the power of AI to bear at <a href=\"https://wise.com/\" target=\"_blank\" rel=\"ugc noopener noreferrer\"><em>Wise</em></a>, across domains as varied as trading algorithms for Treasury, fraud detection, experiment analysis and causal inference, and recently the numerous applications unlocked by large language models. Open-source projects initiated and guided by Egor include wise-pizza, causaltune, and neural-lifetimes, with more on the way.\n</p>\n<p>Machine Learning, AI Agents, and Autonomy // MLOps Podcast #282 with Egor Kraev, Head of AI at Wise Plc.\n\n// Abstract\nDemetrios chats with Egor Kraev, principal AI scientist at Wise, about integrating large language models (LLMs) to enhance ML pipelines and humanize data interactions. Egor discusses his open-source MotleyCrew framework, career journey, and insights into AI's role in fintech, highlighting its potential to streamline operations and transform organizations.\n\n// Bio\nEgor first learned mathematics in the Russian tradition, then continued his studies at ETH Zurich and the University of Maryland. Egor has been doing data science since last century, including economic and human development data analysis for nonprofits in the US, the UK, and Ghana, and 10 years as a quant, solutions architect, and occasional trader at UBS then Deutsche Bank. Following last decade's explosion in AI techniques, Egor became Head of AI at Mosaic Smart Data Ltd, and for the last four years is bringing the power of AI to bear at Wise, in a variety of domains, from fraud detection to trading algorithms and causal inference for A/B testing and marketing. Egor has multiple side projects such as RL for molecular optimization, GenAI for generating and solving high school math problems, and others. \n\n// MLOps Swag/Merch\n<a href=\"https://shop.mlops.community/\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://shop.mlops.community/</a>\n\n// Related Links\n<a href=\"https://github.com/transferwise/wise-pizza\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://github.com/transferwise/wise-pizza</a>\n<a href=\"https://github.com/py-why/causaltune\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://github.com/py-why/causaltune</a>\n<a href=\"https://www.linkedin.com/posts/egorkraev_a-talk-on-experimentation-best-practices-activity-7092158531247755265-q0kt?utm_source=share&amp;utm_medium=member_desktop \" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://www.linkedin.com/posts/egorkraev_a-talk-on-experimentation-best-practices-activity-7092158531247755265-q0kt?utm_source=share&amp;utm_medium=member_desktop </a>\n \n--------------- ✌️Connect With Us ✌️ -------------\nJoin our slack community: <a href=\"https://go.mlops.community/slack\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://go.mlops.community/slack</a>\nFollow us on Twitter: <a href=\"@mlopscommunity\" target=\"_blank\" rel=\"ugc noopener noreferrer\">@mlopscommunity</a>\nSign up for the next meetup: <a href=\"https://go.mlops.community/register\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://go.mlops.community/register</a>\nCatch all episodes, blogs, newsletters, and more: <a href=\"https://mlops.community/\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://mlops.community/</a>\n\nConnect with Demetrios on LinkedIn: <a href=\"https://www.linkedin.com/in/dpbrinkm/\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://www.linkedin.com/in/dpbrinkm/</a>\nConnect with Egor on LinkedIn: <a href=\"https://www.linkedin.com/in/egorkraev/\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://www.linkedin.com/in/egorkraev/</a>\n\n</p>\n</ituneshack>","flags":null,"enclosureUrl":"https://anchor.fm/s/174cb1b8/podcast/play/96727396/https%3A%2F%2Fd3ctxlq1ktw2nl.cloudfront.net%2Fstaging%2F2025-0-7%2F392674585-44100-2-6ae032f481f05.mp3","enclosureMime":""},{"title":"Re-Platforming Your Tech Stack // Michelle Marie Conway & Andrew Baker // #281","url":"https://podcasters.spotify.com/pod/show/mlops/episodes/Re-Platforming-Your-Tech-Stack--Michelle-Marie-Conway--Andrew-Baker--281-e2t1aq9","date":1735927992,"author":"Demetrios Brinkmann","unread":true,"content":"<ituneshack><p>Re-Platforming Your Tech Stack // MLOps Podcast #281 with Michelle Marie Conway, Lead Data Scientist at Lloyds Banking Group and Andrew Baker, Data Science Delivery Lead at Lloyds Banking Group.\n\n// Abstract\nLloyds Banking Group is on a mission to embrace the power of cloud and unlock the opportunities that it provides. Andrew, Michelle, and their MLOps team have been on a journey over the last 12 months to take their portfolio of circa 10 Machine Learning models in production and migrate them from an on-prem solution to a cloud-based environment. During the podcast, Michelle and Andrew share their reflections as well as some dos (and don’ts!) of managing the migration of an established portfolio.\n\n// Bio\nMichelle Marie Conway\nMichelle is a Lead Data Scientist in the high-performance data science team at Lloyds Banking Group. With deep expertise in managing production-level Python code and machine learning models, she has worked alongside fellow senior manager Andrew to drive the bank's transition to the Google Cloud Platform. Together, they have played a pivotal role in modernising the ML portfolio in collaboration with a remarkable ML Ops team.\n\nOriginally from Ireland and now based in London, Michelle blends her technical expertise with a love for the arts. \n\nAndrew Baker\nAndrew graduated from the University of Birmingham with a first-class honours degree in Mathematics and Music with a Year in Computer Science and joined Lloyds Banking Group on their Retail graduate scheme in 2015.\n\nSince 2021 Andrew has worked in the world of data, firstly in shaping the Retail data strategy and most recently as a Data Science Delivery Lead, growing and managing a team of Data Scientists and Machine Learning Engineers. He has built a high-performing team responsible for building and maintaining ML models in production for the Consumer Lending division of the bank.\n\nAndrew is motivated by the role that data science and ML can play in transforming the business and its processes, and is focused on balancing the power of ML with the need for simplicity and explainability that enables business users to engage with the opportunities that exist in this space and the demands of a highly regulated environment.\n\n// MLOps Swag/Merch\nhttps://shop.mlops.community/\n\n// Related Links\nWebsite: https://www.michelleconway.co.uk/\nhttps://www.linkedin.com/pulse/artificial-intelligence-just-when-data-science-answer-andrew-baker-hfdge/\nhttps://www.linkedin.com/pulse/artificial-intelligence-conundrum-generative-ai-andrew-baker-qla7e/ \n \n--------------- ✌️Connect With Us ✌️ -------------\nJoin our slack community: https://go.mlops.community/slack\nFollow us on Twitter: @mlopscommunity\nSign up for the next meetup: https://go.mlops.community/register\nCatch all episodes, blogs, newsletters, and more: https://mlops.community/\n\nConnect with Demetrios on LinkedIn: https://www.linkedin.com/in/dpbrinkm/\nConnect with Michelle on LinkedIn: https://www.linkedin.com/in/michelle--conway/\nConnect with Andrew on LinkedIn: https://www.linkedin.com/in/andrew-baker-90952289\n\n</p>\n</ituneshack>","flags":null,"enclosureUrl":"https://anchor.fm/s/174cb1b8/podcast/play/96561417/https%3A%2F%2Fd3ctxlq1ktw2nl.cloudfront.net%2Fstaging%2F2025-0-3%2F392469992-44100-2-bcad12a952aae.mp3","enclosureMime":""},{"title":"Holistic Evaluation of Generative AI Systems // Jineet Doshi // #280","url":"https://podcasters.spotify.com/pod/show/mlops/episodes/Holistic-Evaluation-of-Generative-AI-Systems--Jineet-Doshi--280-e2smc2j","date":1734982066,"author":"Demetrios Brinkmann","unread":true,"content":"<ituneshack><p><a href=\"https://www.linkedin.com/in/jineetdoshi/\" target=\"_blank\" rel=\"ugc noopener noreferrer\"><em>Jineet Doshi</em></a> is an award-winning Scientist, Machine Learning Engineer, and Leader at <a href=\"https://www.intuit.com/\" target=\"_blank\" rel=\"ugc noopener noreferrer\"><em>Intuit</em></a> with over 7 years of experience. He has a proven track record of leading successful AI projects and building machine-learning models from design to production across various domains which have impacted 100 million customers and significantly improved business metrics, leading to millions of dollars of impact.\n</p>\n<p>Holistic Evaluation of Generative AI Systems // MLOps Podcast #280 with Jineet Doshi, Staff AI Scientist or AI Lead at Intuit.\n\n// Abstract\nEvaluating LLMs is essential in establishing trust before deploying them to production. Even post deployment, evaluation is essential to ensure LLM outputs meet expectations, making it a foundational part of LLMOps. However, evaluating LLMs remains an open problem. Unlike traditional machine learning models, LLMs can perform a wide variety of tasks such as writing poems, Q&amp;A, summarization etc. This leads to the question how do you evaluate a system with such broad intelligence capabilities? This talk covers the various approaches for evaluating LLMs such as classic NLP techniques, red teaming and newer ones like using LLMs as a judge, along with the pros and cons of each. The talk includes evaluation of complex GenAI systems like RAG and Agents. It also covers evaluating LLMs for safety and security and the need to have a holistic approach for evaluating these very capable models.\n\n// Bio\nJineet Doshi is an award winning AI Lead and Engineer with over 7 years of experience. He has a proven track record of leading successful AI projects and building machine learning models from design to production across various domains, which have impacted millions of customers and have significantly improved business metrics, leading to millions of dollars of impact. He is currently an AI Lead at Intuit where he is one of the architects and developers of their Generative AI platform, which is serving Generative AI experiences for more than 100 million customers around the world.\n\nJineet is also a guest lecturer at Stanford University as part of their building LLM Applications class. He is on the Advisory Board of University of San Francisco’s AI Program. He holds multiple patents in the field, is on the steering committee of MLOps World Conference and has also co chaired workshops at top AI conferences like KDD. He holds a Masters degree from Carnegie Mellon university.\n\n// MLOps Swag/Merch\n<a href=\"https://shop.mlops.community/\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://shop.mlops.community/</a>\n\n// Related Links\n<a target=\"_blank\" rel=\"ugc noopener noreferrer\">Website: https://www.intuit.com/</a>\n \n--------------- ✌️Connect With Us ✌️ -------------\nJoin our slack community: <a href=\"https://go.mlops.community/slack\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://go.mlops.community/slack</a>\nFollow us on Twitter: <a href=\"@mlopscommunity\" target=\"_blank\" rel=\"ugc noopener noreferrer\">@mlopscommunity</a>\nSign up for the next meetup: <a href=\"https://go.mlops.community/register\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://go.mlops.community/register</a>\nCatch all episodes, blogs, newsletters, and more: <a href=\"https://mlops.community/\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://mlops.community/</a>\n\nConnect with Demetrios on LinkedIn: <a href=\"https://www.linkedin.com/in/dpbrinkm/\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://www.linkedin.com/in/dpbrinkm/</a>\nConnect with Jineet on LinkedIn: <a href=\"https://www.linkedin.com/in/jineetdoshi/\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://www.linkedin.com/in/jineetdoshi/</a></p>\n</ituneshack>","flags":null,"enclosureUrl":"https://anchor.fm/s/174cb1b8/podcast/play/96202259/https%3A%2F%2Fd3ctxlq1ktw2nl.cloudfront.net%2Fstaging%2F2024-11-23%2F392025719-44100-2-6aba9ca4c13cf.mp3","enclosureMime":""},{"title":"Unleashing Unconstrained News Knowledge Graphs to Combat Misinformation // Robert Caulk // #279","url":"https://podcasters.spotify.com/pod/show/mlops/episodes/Unleashing-Unconstrained-News-Knowledge-Graphs-to-Combat-Misinformation--Robert-Caulk--279-e2sis0d","date":1734712634,"author":"Demetrios Brinkmann","unread":true,"content":"<ituneshack><p><em></em><a href=\"https://www.linkedin.com/in/rcaulk/\" target=\"_blank\" rel=\"ugc noopener noreferrer\"><em>Robert Caulk</em></a> is responsible for directing software development, enabling research, coordinating company projects, quality control, proposing external collaborations, and securing funding. He believes firmly in open-source, having spent 12 years accruing over 1000 academic citations building open-source software in domains such as machine learning, image analysis, and coupled physical processes. He received his Ph.D. from Université Grenoble Alpes, France, in computational mechanics.\n\nUnleashing Unconstrained News Knowledge Graphs to Combat Misinformation // MLOps Podcast #279 with Robert Caulk, Founder of Emergent Methods.\n\n// Abstract\nIndexing hundreds of thousands of news articles per day into a knowledge graph (KG) was previously impossible due to the strict requirement that high-level reasoning, general world knowledge, and full-text context *must* be present for proper KG construction.\n\nThe latest tools now enable such general world knowledge and reasoning to be applied cost effectively to high-volumes of news articles. Beyond the low cost of processing these news articles, these tools are also opening up a new, controversial, approach to KG building - unconstrained KGs. \n\nWe discuss the construction and exploration of the largest news-knowledge-graph on the planet - hosted on an endpoint at AskNews.app. During talk we aim to highlight some of the sacrifices and benefits that go hand-in-hand with using the infamous unconstrained KG approach.\n\nWe conclude the talk by explaining how knowledge graphs like these help to mitigate misinformation. We provide some examples of how our clients are using this graph, such as generating sports forecasts, generating better social media posts, generating regional security alerts, and combating human trafficking.\n\n// Bio\nRobert is the founder of Emergent Methods, where he directs research and software development for large-scale applications. He is currently overseeing the structuring of hundreds of thousands of news articles per day in order to build the best news retrieval API in the world: https://asknews.app. \n\n// MLOps Swag/Merch</p>\n<p><a href=\"https://shop.mlops.community/\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://shop.mlops.community/</a>\n\n// Related Links\nWebsite: <a href=\"https://emergentmethods.ai\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://emergentmethods.ai</a></p>\n<p>News Retrieval API: <a href=\"https://asknews.app\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://asknews.app</a>\n \n--------------- ✌️Connect With Us ✌️ -------------\nJoin our slack community: <a href=\"https://go.mlops.community/slack\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://go.mlops.community/slack</a>\nFollow us on Twitter: <a href=\"@mlopscommunity\" target=\"_blank\" rel=\"ugc noopener noreferrer\">@mlopscommunity</a>\nSign up for the next meetup: <a href=\"https://go.mlops.community/register\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://go.mlops.community/register</a>\nCatch all episodes, blogs, newsletters, and more: <a href=\"https://mlops.community/\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://mlops.community/</a>\n\nConnect with Demetrios on LinkedIn: <a href=\"https://www.linkedin.com/in/dpbrinkm/\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://www.linkedin.com/in/dpbrinkm/</a>\nConnect with Rob on LinkedIn: <a href=\"https://www.linkedin.com/in/rcaulk/\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://www.linkedin.com/in/rcaulk/</a></p>\n<p>\nTimestamps:\n[00:00] Rob's preferred coffee\n[00:05] Takeaways\n[00:55] Please like, share, leave a review, and subscribe to our MLOps channels!\n[01:00] Join our Local Organizer Carousel!\n[02:15] Knowledge Graphs and ontology\n[07:43] Ontology vs Noun Approach\n[12:46] Ephemeral tools for efficiency\n[17:26] Oracle to PostgreSQL migration\n[22:20] MEM Graph life cycle\n[29:14] Knowledge Graph Investigation Insights\n[33:37] Fine-tuning and distillation of LLMs\n[39:28] DAG workflow and quality control\n[46:23] Crawling nodes with Phi 3 Llama\n[50:05] AI pricing risks and strategies\n[56:14] Data labeling and poisoning\n[58:34] API costs vs News latency\n[1:02:10] Product focus and value\n[1:04:52] Ensuring reliable information\n[1:11:01] Podcast transcripts as News\n[1:13:08] Ontology trade-offs explained\n[1:15:00] Wrap up</p>\n</ituneshack>","flags":null,"enclosureUrl":"https://anchor.fm/s/174cb1b8/podcast/play/96087501/https%3A%2F%2Fd3ctxlq1ktw2nl.cloudfront.net%2Fstaging%2F2024-11-20%2F391880580-44100-2-d57545176debf.mp3","enclosureMime":""},{"title":"LLM Distillation and Compression // Guanhua Wang // #278","url":"https://podcasters.spotify.com/pod/show/mlops/episodes/LLM-Distillation-and-Compression--Guanhua-Wang--278-e2sebhr","date":1734455373,"author":"Demetrios Brinkmann","unread":true,"content":"<ituneshack><p><a href=\"https://www.linkedin.com/in/guanhua-wang/\" target=\"_blank\" rel=\"ugc noopener noreferrer\"><em>Guanhua Wang</em></a> is <em>a Senior Researcher</em> in DeepSpeed Team at <em>Microsoft</em>. Before <em>Microsoft</em>, Guanhua earned his Computer Science PhD from UC Berkeley.\n\nDomino: Communication-Free LLM Training Engine // MLOps Podcast #278 with Guanhua \"Alex\" Wang, Senior Researcher at Microsoft.\n\n// Abstract\nGiven the popularity of generative AI, Large Language Models (LLMs) often consume hundreds or thousands of GPUs to parallelize and accelerate the training process. Communication overhead becomes more pronounced when training LLMs at scale. To eliminate communication overhead in distributed LLM training, we propose Domino, which provides a generic scheme to hide communication behind computation. By breaking the data dependency of a single batch training into smaller independent pieces, Domino pipelines these independent pieces of training and provides a generic strategy of fine-grained communication and computation overlapping. Extensive results show that compared with Megatron-LM, Domino achieves up to 1.3x speedup for LLM training on Nvidia DGX-H100 GPUs.\n\n// Bio\nGuanhua Wang is a Senior Researcher in the DeepSpeed team at Microsoft. His research focuses on large-scale LLM training and serving. Previously, he led the ZeRO++ project at Microsoft which helped reduce over half of model training time inside Microsoft and Linkedin. He also led and was a major contributor to Microsoft Phi-3 model training. He holds a CS PhD from UC Berkeley advised by Prof Ion Stoica. \n\n// MLOps Swag/Merch\n<a href=\"https://shop.mlops.community/\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://shop.mlops.community/</a>\n\n// Related Links\nWebsite: <a href=\"https://guanhuawang.github.io/\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://guanhuawang.github.io/</a>\nDeepSpeed hiring: <a href=\"https://www.microsoft.com/en-us/research/project/deepspeed/opportunities/\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://www.microsoft.com/en-us/research/project/deepspeed/opportunities/</a></p>\n<p>Large Model Training and Inference with DeepSpeed // Samyam Rajbhandari // LLMs in Prod Conference: <a href=\"https://youtu.be/cntxC3g22oU\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://youtu.be/cntxC3g22oU</a>\n \n--------------- ✌️Connect With Us ✌️ -------------\nJoin our slack community: <a href=\"https://go.mlops.community/slack\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://go.mlops.community/slack</a>\nFollow us on Twitter: <a href=\"@mlopscommunity\" target=\"_blank\" rel=\"ugc noopener noreferrer\">@mlopscommunity</a>\nSign up for the next meetup: <a href=\"https://go.mlops.community/register\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://go.mlops.community/register</a>\nCatch all episodes, blogs, newsletters, and more: <a href=\"https://mlops.community/\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://mlops.community/</a>\n\nConnect with Demetrios on LinkedIn: <a href=\"https://www.linkedin.com/in/dpbrinkm/\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://www.linkedin.com/in/dpbrinkm/</a>\nConnect with Guanhua on LinkedIn: <a href=\"https://www.linkedin.com/in/guanhua-wang/\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://www.linkedin.com/in/guanhua-wang/</a>\n\nTimestamps:\n[00:00] Guanhua's preferred coffee\n[00:17] Takeaways\n[01:36] Please like, share, leave a review, and subscribe to our MLOps channels!\n[01:47] Phi model explanation\n[06:29] Small Language Models optimization challenges\n[07:29] DeepSpeed overview and benefits\n[10:58] Crazy unimplemented crazy AI ideas\n[17:15] Post training vs QAT\n[19:44] Quantization over distillation\n[24:15] Using Lauras \n[27:04] LLM scaling sweet spot\n[28:28] Quantization techniques\n[32:38] Domino overview\n[38:02] Training performance benchmark\n[42:44] Data dependency-breaking strategies\n[49:14] Wrap up</p>\n</ituneshack>","flags":null,"enclosureUrl":"https://anchor.fm/s/174cb1b8/podcast/play/95939579/https%3A%2F%2Fd3ctxlq1ktw2nl.cloudfront.net%2Fstaging%2F2024-11-17%2F391693039-44100-2-29c2d2f312cdf.mp3","enclosureMime":""}]}